# Default values for charts.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Count of batch inference workers
workersCount: 1

# Resource settings for batch inference instance
resources:
  requests:
    cpu: 19
    memory: 93604421089
  limits:
    cpu: 19
    memory: 93604421089

# Shorthands for setting both limits and requests of batch inference instance's cpu/memory
cpu: null
memory: null

# Resource settings for batch inference wrapper
batch_wrapper_resources:
  requests:
    cpu: 2
    memory: 1Gi

# Shorthands for setting both limits and requests of wrapper's cpu/memory
wrapper_cpu: null
wrapper_memory: null

# Logging level of batch inference wrapper
logLevel: 'INFO'

# Settings for CLI automatic resource configuration
cpu_fraction: 0.5
memory_fraction: 0.5

# Settings below are not intended to be modified
experimentName: {{ NAUTA.ExperimentName }} 
podCount: 2
registryPort: {{ NAUTA.RegistryPort }}

dataPath: '/mnt/input/home/data'
modelPath: '/mnt/input/home/models'
modelName: ''
outputPath: '/mnt/output/experiment'
inputFormat: 'pb'

containerPort: 8500

image:
  pullPolicy: IfNotPresent
  clusterRepository: {{ NAUTA.ExperimentImage }}

offline_registry: "true"